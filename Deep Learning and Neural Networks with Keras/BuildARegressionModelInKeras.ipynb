{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM: Introduction to Deep Learning & Neural Networks Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Regression Model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Build a baseline model.\n",
    "Use the Keras library to build a neural network with the following:\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error  as the loss function.\n",
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to predictors and target\n",
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get number of predictors as inputs for network\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,))) # first layer must match number of inputs\n",
    "    model.add(Dense(1)) # One output value\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 121.07828475952148\n",
      "Standard Deviation: 28.916516744971265\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model = regression_model()\n",
    "errors = []\n",
    "for i in range(50):\n",
    "    # Step 1: Randomly split dataset to training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3)\n",
    "\n",
    "    # Step 2: Train the model on the training data using 50 epochs\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50)\n",
    "\n",
    "    # Step 3: Evaluate the model on the test data and compute the mean squared error\n",
    "    errors.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "    print('Run {} out of 50'.format(i + 1), end='\\r')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanMSE_Part_A = np.mean(errors)\n",
    "stdDev_Part_A = np.std(errors)\n",
    "print('Mean MSE: {}\\nStandard Deviation: {}'.format(meanMSE_Part_A, stdDev_Part_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Normalize the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part A but use a normalized version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize predictors\n",
    "\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 52.0611413192749\n",
      "Standard Deviation: 98.26574546555324\n",
      "Normalizing values reduced mean MSE by 57.00208222913327 percent from part A\n"
     ]
    }
   ],
   "source": [
    "# Re-run the model on normalized predictors\n",
    "model = regression_model()\n",
    "errors = []\n",
    "for i in range(50):\n",
    "    # Step 1: Randomly split dataset to training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "\n",
    "    # Step 2: Train the model on the training data using 50 epochs\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50)\n",
    "\n",
    "    # Step 3: Evaluate the model on the test data and compute the mean squared error\n",
    "    errors.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "    print('Run {} out of 50'.format(i + 1), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanMSE_Part_B = np.mean(errors)\n",
    "improvement = 100 * (meanMSE_Part_A - meanMSE_Part_B) / meanMSE_Part_A\n",
    "stdDev_Part_B = np.std(errors)\n",
    "print('Mean MSE: {}\\nStandard Deviation: {}'.format(meanMSE_Part_B, stdDev_Part_B))\n",
    "print('Normalizing values reduced mean MSE by {} percent from part A'.format(improvement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data decreased the MSE by about 57% from Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Increase the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Part B but use 100 epochs this time for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  49  out of 100\r"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(50):\n",
    "    # Step 1: Randomly split dataset to training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "\n",
    "    # Step 2: Train the model on the training data using 50 epochs\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "\n",
    "    # Step 3: Evaluate the model on the test data and compute the mean squared error\n",
    "    errors.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "    print('Run {} out of 50'.format(i + 1), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 23.65131546020508\n",
      "Standard Deviation: 2.5576829442248354\n",
      "Increasing epochs from 50 to 100 reduced mean MSE by 54.57011724894991 percent from part B\n"
     ]
    }
   ],
   "source": [
    "meanMSE_Part_C = np.mean(errors)\n",
    "improvement = 100 * (meanMSE_Part_B - meanMSE_Part_C) / meanMSE_Part_B\n",
    "stdDev_Part_C = np.std(errors)\n",
    "print('Mean MSE: {}\\nStandard Deviation: {}'.format(meanMSE_Part_C, stdDev_Part_C))\n",
    "print('Increasing epochs from 50 to 100 reduced mean MSE by {} percent from part B'.format(improvement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the epochs from 50 to 100 reduced the MSE by about 55% from Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Increase the number of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat part B but use a neural network with three hidden layers, each with 10 nodes and a ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_model():\n",
    "        # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,))) # first layer must match number of inputs\n",
    "    model.add(Dense(10, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"relu\"))\n",
    "    model.add(Dense(1)) # One output value\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0\n",
      "Run  1  out of 50\n",
      "Run  2  out of 50\n",
      "Run  3  out of 50\n",
      "Run  4  out of 50\n",
      "Run  5  out of 50\n",
      "Run  6  out of 50\n",
      "Run  7  out of 50\n",
      "Run  8  out of 50\n",
      "Run  9  out of 50\n",
      "Run  10 out of 50\n",
      "Run  11  out of 50\n",
      "Run  12  out of 50\n",
      "Run  13  out of 50\n",
      "Run  14  out of 50\n",
      "Run  15  out of 50\n",
      "Run  16  out of 50\n",
      "Run  17  out of 50\n",
      "Run  18  out of 50\n",
      "Run  19  out of 50\n",
      "Run  20  out of 50\n",
      "Run  21  out of 50\n",
      "Run  22  out of 50\n",
      "Run  23  out of 50\n",
      "Run  24  out of 50\n",
      "Run  25  out of 50\n",
      "Run  26  out of 50\n",
      "Run  27  out of 50\n",
      "Run  28  out of 50\n",
      "Run  29  out of 50\n",
      "Run  30  out of 50\n",
      "Run  31  out of 50\n",
      "Run  32  out of 50\n",
      "Run  33  out of 50\n",
      "Run  34  out of 50\n",
      "Run  35  out of 50\n",
      "Run  36  out of 50\n",
      "Run  37  out of 50\n",
      "Run  38  out of 50\n",
      "Run  39  out of 50\n",
      "Run  40  out of 50\n",
      "Run  41  out of 50\n",
      "Run  42  out of 50\n",
      "Run  43  out of 50\n",
      "Run  44  out of 50\n",
      "Run  45  out of 50\n",
      "Run  46  out of 50\n",
      "Run  47  out of 50\n",
      "Run  48  out of 50\n",
      "Run  49  out of 50\n",
      "Run  49  out of 50\r"
     ]
    }
   ],
   "source": [
    "# Run the evaluation of the new model\n",
    "model = three_layer_model()\n",
    "errors = []\n",
    "for i in range(50):\n",
    "    print('Run ', i)\n",
    "    # Step 1: Randomly split dataset to training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "\n",
    "    # Step 2: Train the model on the training data using 50 epochs\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50)\n",
    "\n",
    "    # Step 3: Evaluate the model on the test data and compute the mean squared error\n",
    "    errors.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "    print('Run {} out of 50'.format(i + 1), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 37.86726760864258\n",
      "Standard Deviation: 25.10171780864401\n",
      "Adding two more hidden layers decreased mean MSE by 37.483226562121445 percent from part B\n"
     ]
    }
   ],
   "source": [
    "meanMSE_Part_D = np.mean(errors)\n",
    "improvement = 100 * (meanMSE_Part_B - meanMSE_Part_D) / meanMSE_Part_D\n",
    "stdDev_Part_D = np.std(errors)\n",
    "print('Mean MSE: {}\\nStandard Deviation: {}'.format(meanMSE_Part_D, stdDev_Part_D))\n",
    "print('Adding two more hidden layers decreased mean MSE by {} percent from part B'.format(improvement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding two more hidden layers reduced the error by about 37% from part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
